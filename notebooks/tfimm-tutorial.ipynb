{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a66f18ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import pprint\n",
    "from dataclasses import dataclass, fields\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import tfimm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122cc937",
   "metadata": {},
   "source": [
    "## Creating models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b3c0e2",
   "metadata": {},
   "source": [
    "### Which models are available?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62170474",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cait_m36_384',\n",
       " 'cait_m48_448',\n",
       " 'cait_s24_224',\n",
       " 'cait_s24_384',\n",
       " 'cait_s36_384',\n",
       " 'cait_xs24_384',\n",
       " 'cait_xxs24_224',\n",
       " 'cait_xxs24_384',\n",
       " 'cait_xxs36_224',\n",
       " 'cait_xxs36_384',\n",
       " 'convmixer_768_32',\n",
       " 'convmixer_1024_20_ks9_p14',\n",
       " 'convmixer_1536_20',\n",
       " 'convnext_base',\n",
       " 'convnext_base_384_in22ft1k',\n",
       " 'convnext_base_in22ft1k',\n",
       " 'convnext_base_in22k',\n",
       " 'convnext_large',\n",
       " 'convnext_large_384_in22ft1k',\n",
       " 'convnext_large_in22ft1k',\n",
       " 'convnext_large_in22k',\n",
       " 'convnext_small',\n",
       " 'convnext_small_384_in22ft1k',\n",
       " 'convnext_small_in22ft1k',\n",
       " 'convnext_small_in22k',\n",
       " 'convnext_tiny',\n",
       " 'convnext_tiny_384_in22ft1k',\n",
       " 'convnext_tiny_in22ft1k',\n",
       " 'convnext_tiny_in22k',\n",
       " 'convnext_xlarge_384_in22ft1k',\n",
       " 'convnext_xlarge_in22ft1k',\n",
       " 'convnext_xlarge_in22k',\n",
       " 'deit_base_distilled_patch16_224',\n",
       " 'deit_base_distilled_patch16_384',\n",
       " 'deit_base_patch16_224',\n",
       " 'deit_base_patch16_384',\n",
       " 'deit_small_distilled_patch16_224',\n",
       " 'deit_small_patch16_224',\n",
       " 'deit_tiny_distilled_patch16_224',\n",
       " 'deit_tiny_patch16_224',\n",
       " 'ecaresnet26t',\n",
       " 'ecaresnet50d',\n",
       " 'ecaresnet50t',\n",
       " 'ecaresnet101d',\n",
       " 'ecaresnet269d',\n",
       " 'ecaresnetlight',\n",
       " 'gmixer_12_224',\n",
       " 'gmixer_24_224',\n",
       " 'gmlp_b16_224',\n",
       " 'gmlp_s16_224',\n",
       " 'gmlp_ti16_224',\n",
       " 'ig_resnext101_32x8d',\n",
       " 'ig_resnext101_32x16d',\n",
       " 'ig_resnext101_32x32d',\n",
       " 'ig_resnext101_32x48d',\n",
       " 'mixer_b16_224',\n",
       " 'mixer_b16_224_in21k',\n",
       " 'mixer_b16_224_miil',\n",
       " 'mixer_b16_224_miil_in21k',\n",
       " 'mixer_b32_224',\n",
       " 'mixer_l16_224',\n",
       " 'mixer_l16_224_in21k',\n",
       " 'mixer_l32_224',\n",
       " 'mixer_s16_224',\n",
       " 'mixer_s32_224',\n",
       " 'pit_b_224',\n",
       " 'pit_b_distilled_224',\n",
       " 'pit_s_224',\n",
       " 'pit_s_distilled_224',\n",
       " 'pit_ti_224',\n",
       " 'pit_ti_distilled_224',\n",
       " 'pit_xs_224',\n",
       " 'pit_xs_distilled_224',\n",
       " 'poolformer_m36',\n",
       " 'poolformer_m48',\n",
       " 'poolformer_s12',\n",
       " 'poolformer_s24',\n",
       " 'poolformer_s36',\n",
       " 'pvt_large',\n",
       " 'pvt_medium',\n",
       " 'pvt_small',\n",
       " 'pvt_tiny',\n",
       " 'pvt_v2_b0',\n",
       " 'pvt_v2_b1',\n",
       " 'pvt_v2_b2',\n",
       " 'pvt_v2_b3',\n",
       " 'pvt_v2_b4',\n",
       " 'pvt_v2_b5',\n",
       " 'resmlp_12_224',\n",
       " 'resmlp_12_224_dino',\n",
       " 'resmlp_12_distilled_224',\n",
       " 'resmlp_24_224',\n",
       " 'resmlp_24_224_dino',\n",
       " 'resmlp_24_distilled_224',\n",
       " 'resmlp_36_224',\n",
       " 'resmlp_36_distilled_224',\n",
       " 'resmlp_big_24_224',\n",
       " 'resmlp_big_24_224_in22ft1k',\n",
       " 'resmlp_big_24_distilled_224',\n",
       " 'resnet18',\n",
       " 'resnet18d',\n",
       " 'resnet26',\n",
       " 'resnet26d',\n",
       " 'resnet26t',\n",
       " 'resnet34',\n",
       " 'resnet34d',\n",
       " 'resnet50',\n",
       " 'resnet50_gn',\n",
       " 'resnet50d',\n",
       " 'resnet101',\n",
       " 'resnet101d',\n",
       " 'resnet152',\n",
       " 'resnet152d',\n",
       " 'resnet200d',\n",
       " 'resnetblur50',\n",
       " 'resnetrs50',\n",
       " 'resnetrs101',\n",
       " 'resnetrs152',\n",
       " 'resnetrs200',\n",
       " 'resnetrs270',\n",
       " 'resnetrs350',\n",
       " 'resnetrs420',\n",
       " 'resnetv2_50x1_bit_distilled',\n",
       " 'resnetv2_50x1_bitm',\n",
       " 'resnetv2_50x1_bitm_in21k',\n",
       " 'resnetv2_50x3_bitm',\n",
       " 'resnetv2_50x3_bitm_in21k',\n",
       " 'resnetv2_101x1_bitm',\n",
       " 'resnetv2_101x1_bitm_in21k',\n",
       " 'resnetv2_101x3_bitm',\n",
       " 'resnetv2_101x3_bitm_in21k',\n",
       " 'resnetv2_152x2_bit_teacher',\n",
       " 'resnetv2_152x2_bit_teacher_384',\n",
       " 'resnetv2_152x2_bitm',\n",
       " 'resnetv2_152x2_bitm_in21k',\n",
       " 'resnetv2_152x4_bitm',\n",
       " 'resnetv2_152x4_bitm_in21k',\n",
       " 'resnext50_32x4d',\n",
       " 'resnext50d_32x4d',\n",
       " 'resnext101_32x8d',\n",
       " 'seresnet50',\n",
       " 'seresnet152d',\n",
       " 'seresnext26d_32x4d',\n",
       " 'seresnext26t_32x4d',\n",
       " 'seresnext50_32x4d',\n",
       " 'ssl_resnet18',\n",
       " 'ssl_resnet50',\n",
       " 'ssl_resnext50_32x4d',\n",
       " 'ssl_resnext101_32x4d',\n",
       " 'ssl_resnext101_32x8d',\n",
       " 'ssl_resnext101_32x16d',\n",
       " 'swin_base_patch4_window7_224',\n",
       " 'swin_base_patch4_window7_224_in22k',\n",
       " 'swin_base_patch4_window12_384',\n",
       " 'swin_base_patch4_window12_384_in22k',\n",
       " 'swin_large_patch4_window7_224',\n",
       " 'swin_large_patch4_window7_224_in22k',\n",
       " 'swin_large_patch4_window12_384',\n",
       " 'swin_large_patch4_window12_384_in22k',\n",
       " 'swin_small_patch4_window7_224',\n",
       " 'swin_tiny_patch4_window7_224',\n",
       " 'swsl_resnet18',\n",
       " 'swsl_resnet50',\n",
       " 'swsl_resnext50_32x4d',\n",
       " 'swsl_resnext101_32x4d',\n",
       " 'swsl_resnext101_32x8d',\n",
       " 'swsl_resnext101_32x16d',\n",
       " 'tv_resnet34',\n",
       " 'tv_resnet50',\n",
       " 'tv_resnet101',\n",
       " 'tv_resnet152',\n",
       " 'tv_resnext50_32x4d',\n",
       " 'vit_base_patch8_224',\n",
       " 'vit_base_patch8_224_in21k',\n",
       " 'vit_base_patch16_224',\n",
       " 'vit_base_patch16_224_in21k',\n",
       " 'vit_base_patch16_224_miil',\n",
       " 'vit_base_patch16_224_miil_in21k',\n",
       " 'vit_base_patch16_384',\n",
       " 'vit_base_patch16_sam_224',\n",
       " 'vit_base_patch32_224',\n",
       " 'vit_base_patch32_224_in21k',\n",
       " 'vit_base_patch32_384',\n",
       " 'vit_base_patch32_sam_224',\n",
       " 'vit_base_r50_s16_224_in21k',\n",
       " 'vit_base_r50_s16_384',\n",
       " 'vit_huge_patch14_224_in21k',\n",
       " 'vit_large_patch16_224',\n",
       " 'vit_large_patch16_224_in21k',\n",
       " 'vit_large_patch16_384',\n",
       " 'vit_large_patch32_224',\n",
       " 'vit_large_patch32_224_in21k',\n",
       " 'vit_large_patch32_384',\n",
       " 'vit_large_r50_s32_224',\n",
       " 'vit_large_r50_s32_224_in21k',\n",
       " 'vit_large_r50_s32_384',\n",
       " 'vit_small_patch16_224',\n",
       " 'vit_small_patch16_224_in21k',\n",
       " 'vit_small_patch16_384',\n",
       " 'vit_small_patch32_224',\n",
       " 'vit_small_patch32_224_in21k',\n",
       " 'vit_small_patch32_384',\n",
       " 'vit_small_r26_s32_224',\n",
       " 'vit_small_r26_s32_224_in21k',\n",
       " 'vit_small_r26_s32_384',\n",
       " 'vit_tiny_patch16_224',\n",
       " 'vit_tiny_patch16_224_in21k',\n",
       " 'vit_tiny_patch16_384',\n",
       " 'vit_tiny_r_s16_p8_224',\n",
       " 'vit_tiny_r_s16_p8_224_in21k',\n",
       " 'vit_tiny_r_s16_p8_384',\n",
       " 'wide_resnet50_2',\n",
       " 'wide_resnet101_2']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfimm.list_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45b9c36b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "213"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tfimm.list_models(pretrained=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1b5de15",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['resnet18',\n",
       " 'resnet18d',\n",
       " 'resnet26',\n",
       " 'resnet26d',\n",
       " 'resnet26t',\n",
       " 'resnet34',\n",
       " 'resnet34d',\n",
       " 'resnet50',\n",
       " 'resnet50_gn',\n",
       " 'resnet50d',\n",
       " 'resnet101',\n",
       " 'resnet101d',\n",
       " 'resnet152',\n",
       " 'resnet152d',\n",
       " 'resnet200d',\n",
       " 'resnetblur50',\n",
       " 'resnetrs50',\n",
       " 'resnetrs101',\n",
       " 'resnetrs152',\n",
       " 'resnetrs200',\n",
       " 'resnetrs270',\n",
       " 'resnetrs350',\n",
       " 'resnetrs420',\n",
       " 'resnetv2_50x1_bit_distilled',\n",
       " 'resnetv2_50x1_bitm',\n",
       " 'resnetv2_50x1_bitm_in21k',\n",
       " 'resnetv2_50x3_bitm',\n",
       " 'resnetv2_50x3_bitm_in21k',\n",
       " 'resnetv2_101x1_bitm',\n",
       " 'resnetv2_101x1_bitm_in21k',\n",
       " 'resnetv2_101x3_bitm',\n",
       " 'resnetv2_101x3_bitm_in21k',\n",
       " 'resnetv2_152x2_bit_teacher',\n",
       " 'resnetv2_152x2_bit_teacher_384',\n",
       " 'resnetv2_152x2_bitm',\n",
       " 'resnetv2_152x2_bitm_in21k',\n",
       " 'resnetv2_152x4_bitm',\n",
       " 'resnetv2_152x4_bitm_in21k']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfimm.list_models(name_filter=\"resnet*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4098ca5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['convnext_base',\n",
       " 'convnext_base_384_in22ft1k',\n",
       " 'convnext_base_in22ft1k',\n",
       " 'convnext_base_in22k',\n",
       " 'convnext_large',\n",
       " 'convnext_large_384_in22ft1k',\n",
       " 'convnext_large_in22ft1k',\n",
       " 'convnext_large_in22k',\n",
       " 'convnext_small',\n",
       " 'convnext_small_384_in22ft1k',\n",
       " 'convnext_small_in22ft1k',\n",
       " 'convnext_small_in22k',\n",
       " 'convnext_tiny',\n",
       " 'convnext_tiny_384_in22ft1k',\n",
       " 'convnext_tiny_in22ft1k',\n",
       " 'convnext_tiny_in22k',\n",
       " 'convnext_xlarge_384_in22ft1k',\n",
       " 'convnext_xlarge_in22ft1k',\n",
       " 'convnext_xlarge_in22k']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfimm.list_models(module=\"convnext\", pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7cea358",
   "metadata": {},
   "source": [
    "### Create a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7140c4f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-24 14:32:57.485955: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "All PyTorch model weights were used when initializing ConvNeXt.\n",
      "All the weights of ConvNeXt were initialized from the PyTorch model.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = tfimm.create_model(\"convnext_tiny\", pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8135ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpdir = tempfile.TemporaryDirectory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "834ab35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfimm_cache_dir = Path(tmpdir.name) / \"cache\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa183328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set this as place where tfimm looks for models\n",
    "tfimm.set_dir(tfimm_cache_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f660629",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-24 14:33:50.647043: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "WARNING:absl:Found untraced functions such as downsample/0_layer_call_fn, downsample/0_layer_call_and_return_conditional_losses, downsample/1_layer_call_fn, downsample/1_layer_call_and_return_conditional_losses, downsample/0_layer_call_fn while saving (showing 5 of 372). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/cw/jgnmtjvj2zn0dtv78bftwtpw0000gn/T/tmpumoxmvbl/cache/convnext_tiny/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/cw/jgnmtjvj2zn0dtv78bftwtpw0000gn/T/tmpumoxmvbl/cache/convnext_tiny/assets\n"
     ]
    }
   ],
   "source": [
    "# Save model to cache\n",
    "model.save(tfimm_cache_dir / \"convnext_tiny\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd5aed5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "# Note that now loading the model does not require reading from cache\n",
    "model = tfimm.create_model(\"convnext_tiny\", pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "afd7f8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpdir.cleanup()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1574a0",
   "metadata": {},
   "source": [
    "### Input size\n",
    "\n",
    "Most models accept arbitrary input sizes out of the box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81d7f136",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tfimm.utils.timm:All PyTorch model weights were used when initializing ConvNeXt.\n",
      "WARNING:tfimm.utils.timm:All the weights of ConvNeXt were initialized from the PyTorch model.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = tfimm.create_model(\"convnext_tiny\", pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c7d2c5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224, 224)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cfg.input_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f4cede53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 1000])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = np.random.uniform(size=(1, 224, 224, 3))\n",
    "res = model(img)\n",
    "res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c40a83dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 1000])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = np.random.uniform(size=(1, 112, 112, 3))\n",
    "res = model(img)\n",
    "res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0fa6b361",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 1000])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = np.random.uniform(size=(1, 32, 32, 3))\n",
    "res = model(img)\n",
    "res.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a9486d",
   "metadata": {},
   "source": [
    "### Number of channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c52a7a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tfimm.utils.timm:All PyTorch model weights were used when initializing ConvNeXt.\n",
      "WARNING:tfimm.utils.timm:All the weights of ConvNeXt were initialized from the PyTorch model.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = tfimm.create_model(\"convnext_tiny\", pretrained=True, in_channels=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "37ae019f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 1000])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = np.random.uniform(size=(1, 224, 224, 1))\n",
    "res = model(img)\n",
    "res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8985a992",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tfimm.utils.timm:All PyTorch model weights were used when initializing ConvNeXt.\n",
      "WARNING:tfimm.utils.timm:All the weights of ConvNeXt were initialized from the PyTorch model.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = tfimm.create_model(\"convnext_tiny\", pretrained=True, in_channels=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f0c301e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 1000])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = np.random.uniform(size=(1, 224, 224, 4))\n",
    "res = model(img)\n",
    "res.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5169ca",
   "metadata": {},
   "source": [
    "### Number of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "33cea177",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tfimm.utils.timm:All PyTorch model weights were used when initializing ConvNeXt.\n",
      "WARNING:tfimm.utils.timm:All the weights of ConvNeXt were initialized from the PyTorch model.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = tfimm.create_model(\"convnext_tiny\", pretrained=True, nb_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d649d28b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 10])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = np.random.uniform(size=(1, 224, 224, 3))\n",
    "res = model(img)\n",
    "res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "45a97375",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tfimm.utils.timm:All PyTorch model weights were used when initializing ConvNeXt.\n",
      "WARNING:tfimm.utils.timm:All the weights of ConvNeXt were initialized from the PyTorch model.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = tfimm.create_model(\"convnext_tiny\", pretrained=True, nb_classes=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0c77a2a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 768])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = np.random.uniform(size=(1, 224, 224, 3))\n",
    "res = model(img)\n",
    "res.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64dd6154",
   "metadata": {},
   "source": [
    "## Using models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449b521c",
   "metadata": {},
   "source": [
    "### Intermediate features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fa33a02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tfimm.create_model(\"convnext_tiny\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4a1b8917",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['stem',\n",
       " 'stage_0/block_0',\n",
       " 'stage_0/block_1',\n",
       " 'stage_0/block_2',\n",
       " 'stage_1/downsample',\n",
       " 'stage_1/block_0',\n",
       " 'stage_1/block_1',\n",
       " 'stage_1/block_2',\n",
       " 'stage_2/downsample',\n",
       " 'stage_2/block_0',\n",
       " 'stage_2/block_1',\n",
       " 'stage_2/block_2',\n",
       " 'stage_2/block_3',\n",
       " 'stage_2/block_4',\n",
       " 'stage_2/block_5',\n",
       " 'stage_2/block_6',\n",
       " 'stage_2/block_7',\n",
       " 'stage_2/block_8',\n",
       " 'stage_3/downsample',\n",
       " 'stage_3/block_0',\n",
       " 'stage_3/block_1',\n",
       " 'stage_3/block_2',\n",
       " 'logits']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e008fbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.random.uniform(size=(1, 224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2889bbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "res, features = model(img, return_features=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b8334a60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "collections.OrderedDict"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e50856fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stem (1, 56, 56, 96)\n",
      "stage_0/block_0 (1, 56, 56, 96)\n",
      "stage_0/block_1 (1, 56, 56, 96)\n",
      "stage_0/block_2 (1, 56, 56, 96)\n",
      "stage_1/downsample (1, 28, 28, 192)\n",
      "stage_1/block_0 (1, 28, 28, 192)\n",
      "stage_1/block_1 (1, 28, 28, 192)\n",
      "stage_1/block_2 (1, 28, 28, 192)\n",
      "stage_2/downsample (1, 14, 14, 384)\n",
      "stage_2/block_0 (1, 14, 14, 384)\n",
      "stage_2/block_1 (1, 14, 14, 384)\n",
      "stage_2/block_2 (1, 14, 14, 384)\n",
      "stage_2/block_3 (1, 14, 14, 384)\n",
      "stage_2/block_4 (1, 14, 14, 384)\n",
      "stage_2/block_5 (1, 14, 14, 384)\n",
      "stage_2/block_6 (1, 14, 14, 384)\n",
      "stage_2/block_7 (1, 14, 14, 384)\n",
      "stage_2/block_8 (1, 14, 14, 384)\n",
      "stage_3/downsample (1, 7, 7, 768)\n",
      "stage_3/block_0 (1, 7, 7, 768)\n",
      "stage_3/block_1 (1, 7, 7, 768)\n",
      "stage_3/block_2 (1, 7, 7, 768)\n",
      "logits (1, 1000)\n"
     ]
    }
   ],
   "source": [
    "for name, value in features.items():\n",
    "    print(name, value.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9099f46",
   "metadata": {},
   "source": [
    "### Saving and loading models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b32ff746",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tfimm.create_model(\"convnext_tiny\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "177a04d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tfimm.architectures.convnext.ConvNeXt"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a91a70ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(model, tf.keras.Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "76f51f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpdir = tempfile.TemporaryDirectory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8a467b70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as downsample/0_layer_call_fn, downsample/0_layer_call_and_return_conditional_losses, downsample/1_layer_call_fn, downsample/1_layer_call_and_return_conditional_losses, downsample/0_layer_call_fn while saving (showing 5 of 372). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/cw/jgnmtjvj2zn0dtv78bftwtpw0000gn/T/tmpbyon738q/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/cw/jgnmtjvj2zn0dtv78bftwtpw0000gn/T/tmpbyon738q/assets\n"
     ]
    }
   ],
   "source": [
    "model.save(tmpdir.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "273b0c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "loaded_model = tf.keras.models.load_model(tmpdir.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f88ce55f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tfimm.architectures.convnext.ConvNeXt"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(loaded_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "88626337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['stem',\n",
       " 'stage_0/block_0',\n",
       " 'stage_0/block_1',\n",
       " 'stage_0/block_2',\n",
       " 'stage_1/downsample',\n",
       " 'stage_1/block_0',\n",
       " 'stage_1/block_1',\n",
       " 'stage_1/block_2',\n",
       " 'stage_2/downsample',\n",
       " 'stage_2/block_0',\n",
       " 'stage_2/block_1',\n",
       " 'stage_2/block_2',\n",
       " 'stage_2/block_3',\n",
       " 'stage_2/block_4',\n",
       " 'stage_2/block_5',\n",
       " 'stage_2/block_6',\n",
       " 'stage_2/block_7',\n",
       " 'stage_2/block_8',\n",
       " 'stage_3/downsample',\n",
       " 'stage_3/block_0',\n",
       " 'stage_3/block_1',\n",
       " 'stage_3/block_2',\n",
       " 'logits']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "95b0c9ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as downsample/0_layer_call_fn, downsample/0_layer_call_and_return_conditional_losses, downsample/1_layer_call_fn, downsample/1_layer_call_and_return_conditional_losses, downsample/0_layer_call_fn while saving (showing 5 of 372). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/cw/jgnmtjvj2zn0dtv78bftwtpw0000gn/T/tmpbyon738q/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/cw/jgnmtjvj2zn0dtv78bftwtpw0000gn/T/tmpbyon738q/assets\n"
     ]
    }
   ],
   "source": [
    "tf.saved_model.save(model, tmpdir.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225b5ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpdir.cleanup()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa894379",
   "metadata": {},
   "source": [
    "## Customization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8eac77d",
   "metadata": {},
   "source": [
    "### Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e021e17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = tfimm.models.model_config(\"convnext_tiny\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a856bca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvNeXtConfig(name='convnext_tiny', url='[timm]', nb_classes=1000, in_channels=3, input_size=(224, 224), patch_size=4, embed_dim=(96, 192, 384, 768), nb_blocks=(3, 3, 9, 3), mlp_ratio=4.0, conv_mlp_block=False, drop_rate=0.0, drop_path_rate=0.1, norm_layer='layer_norm_eps_1e-6', act_layer='gelu', init_scale=1e-06, crop_pct=0.875, interpolation='bicubic', mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), first_conv='stem/0', classifier='head/fc')\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8885839f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: convnext_tiny\n",
      "url: [timm]\n",
      "nb_classes: 1000\n",
      "in_channels: 3\n",
      "input_size: (224, 224)\n",
      "patch_size: 4\n",
      "embed_dim: (96, 192, 384, 768)\n",
      "nb_blocks: (3, 3, 9, 3)\n",
      "mlp_ratio: 4.0\n",
      "conv_mlp_block: False\n",
      "drop_rate: 0.0\n",
      "drop_path_rate: 0.1\n",
      "norm_layer: layer_norm_eps_1e-6\n",
      "act_layer: gelu\n",
      "init_scale: 1e-06\n",
      "crop_pct: 0.875\n",
      "interpolation: bicubic\n",
      "mean: (0.485, 0.456, 0.406)\n",
      "std: (0.229, 0.224, 0.225)\n",
      "first_conv: stem/0\n",
      "classifier: head/fc\n"
     ]
    }
   ],
   "source": [
    "for field in fields(cfg):\n",
    "    print(f\"{field.name}: {getattr(cfg, field.name)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "75319dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tfimm.utils.timm:All PyTorch model weights were used when initializing ConvNeXt.\n",
      "WARNING:tfimm.utils.timm:All the weights of ConvNeXt were initialized from the PyTorch model.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# All these parameters can be set when creating the model\n",
    "model = tfimm.create_model(\n",
    "    \"convnext_tiny\", \n",
    "    pretrained=True,\n",
    "    drop_rate=0.2,  # Dropout before classification layer\n",
    "    drop_path_rate=0.1,  # Stochastic depth\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d3e03d8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cfg.drop_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a1c0eb0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cfg.drop_path_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ace29c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
